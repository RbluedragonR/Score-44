#!/usr/bin/env python3
"""
Production Setup Script for RTX 4090 Score Vision Miner
Sets up optimal configuration and pre-compiles engines for maximum performance.
"""

import os
import sys
import time
import asyncio
from pathlib import Path
from loguru import logger

# Add miner directory to path
miner_dir = str(Path(__file__).resolve().parent.parent)
sys.path.insert(0, miner_dir)

from scripts.download_models import download_models
from scripts.setup_engines import precompile_engines
from utils.model_manager import ModelManager

# Optimal RTX 4090 configuration based on testing
OPTIMAL_CONFIG = {
    "FORCE_SPEED_MODE": "true",
    "BATCH_SIZE": "20",
    "IMAGE_SIZE": "1024",
    "DEVICE": "cuda",
    "SKIP_TENSORRT": "false",  # Use TensorRT for production
    "CONFIDENCE_THRESHOLD": "0.15",
    "IOU_THRESHOLD": "0.35",
    "MAX_CONCURRENT_BATCHES": "2"
}

def setup_environment():
    """Setup environment variables for optimal performance."""
    logger.info("Setting up optimal RTX 4090 environment variables...")
    
    # Create .env file with optimal settings
    env_file = Path(__file__).parent.parent / ".env"
    
    env_content = []
    env_content.append("# RTX 4090 Optimal Configuration for Score Vision Miner")
    env_content.append("# Generated by setup_production.py")
    env_content.append("")
    
    # Add network configuration (user should update these)
    env_content.append("# Network Configuration (UPDATE THESE)")
    env_content.append("NETUID=44")
    env_content.append("SUBTENSOR_NETWORK=finney")
    env_content.append("SUBTENSOR_ADDRESS=wss://entrypoint-finney.opentensor.ai:443")
    env_content.append("WALLET_NAME=default")
    env_content.append("HOTKEY_NAME=default")
    env_content.append("MIN_STAKE_THRESHOLD=1000")
    env_content.append("")
    
    # Add optimal performance settings
    env_content.append("# RTX 4090 Performance Optimization")
    for key, value in OPTIMAL_CONFIG.items():
        env_content.append(f"{key}={value}")
    
    env_content.append("")
    env_content.append("# Additional Performance Settings")
    env_content.append("CUDA_VISIBLE_DEVICES=0")
    env_content.append("PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128")
    env_content.append("OMP_NUM_THREADS=8")
    
    # Write .env file
    with open(env_file, 'w') as f:
        f.write('\n'.join(env_content))
    
    logger.info(f"Environment file created: {env_file}")
    logger.info("Please update WALLET_NAME, HOTKEY_NAME, and network settings in .env")
    
    # Set environment variables for current session
    for key, value in OPTIMAL_CONFIG.items():
        os.environ[key] = value
    
    logger.info("Environment variables set for optimal RTX 4090 performance")

def check_system_requirements():
    """Check system requirements for RTX 4090 optimization."""
    logger.info("Checking system requirements...")
    
    # Check CUDA availability
    try:
        import torch
        if not torch.cuda.is_available():
            logger.error("‚ùå CUDA not available")
            return False
        
        device_name = torch.cuda.get_device_name(0)
        logger.info(f"‚úÖ GPU detected: {device_name}")
        
        if "4090" not in device_name:
            logger.warning(f"‚ö†Ô∏è GPU is not RTX 4090. Optimization may not be optimal.")
        else:
            logger.info("‚úÖ RTX 4090 detected - optimal configuration will be applied")
        
        # Check VRAM
        total_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
        logger.info(f"‚úÖ GPU VRAM: {total_memory:.1f} GB")
        
        if total_memory < 20:
            logger.warning("‚ö†Ô∏è Less than 20GB VRAM - may need to reduce batch size")
        
        return True
        
    except ImportError:
        logger.error("‚ùå PyTorch not installed")
        return False

def optimize_cuda_settings():
    """Apply CUDA optimizations."""
    logger.info("Applying CUDA optimizations...")
    
    try:
        import torch
        
        # Set memory fraction
        torch.cuda.set_per_process_memory_fraction(0.95)
        
        # Enable optimizations
        torch.backends.cudnn.benchmark = True
        torch.backends.cudnn.deterministic = False
        torch.backends.cudnn.allow_tf32 = True
        torch.backends.cuda.matmul.allow_tf32 = True
        
        logger.info("‚úÖ CUDA optimizations applied")
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Failed to apply CUDA optimizations: {e}")
        return False

async def run_performance_test():
    """Run a quick performance test to verify setup."""
    logger.info("Running performance test...")
    
    try:
        from scripts.quick_test import main as quick_test_main
        
        # Run quick test
        start_time = time.time()
        await quick_test_main()
        test_time = time.time() - start_time
        
        logger.info(f"‚úÖ Performance test completed in {test_time:.2f}s")
        
        if test_time < 15:
            logger.info("üöÄ EXCELLENT: Processing time is under 15s limit")
        elif test_time < 20:
            logger.info("‚úÖ GOOD: Processing time is acceptable")
        else:
            logger.warning("‚ö†Ô∏è SLOW: Processing time may be too high for competition")
        
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Performance test failed: {e}")
        return False

def create_startup_script():
    """Create startup script for production deployment."""
    logger.info("Creating startup script...")
    
    startup_script = Path(__file__).parent.parent / "start_miner.sh"
    
    script_content = [
        "#!/bin/bash",
        "# RTX 4090 Optimized Miner Startup Script",
        "# Generated by setup_production.py",
        "",
        "# Set environment variables",
        "export CUDA_VISIBLE_DEVICES=0",
        "export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128",
        "export OMP_NUM_THREADS=8",
        "",
        "# Load environment from .env file",
        "if [ -f .env ]; then",
        "    export $(cat .env | xargs)",
        "fi",
        "",
        "# Start miner with PM2",
        "pm2 start \\",
        "  --name \"sn44-miner-rtx4090\" \\",
        "  --interpreter \"../.venv/bin/python\" \\",
        "  \"../.venv/bin/uvicorn\" \\",
        "  -- main:app --host 0.0.0.0 --port 7999 --workers 1",
        "",
        "echo \"Miner started with RTX 4090 optimizations\"",
        "echo \"Check logs with: pm2 logs sn44-miner-rtx4090\"",
        "echo \"Check status with: pm2 status\"",
    ]
    
    with open(startup_script, 'w') as f:
        f.write('\n'.join(script_content))
    
    # Make script executable
    os.chmod(startup_script, 0o755)
    
    logger.info(f"‚úÖ Startup script created: {startup_script}")

def print_final_instructions():
    """Print final setup instructions."""
    print("\n" + "="*70)
    print("RTX 4090 PRODUCTION SETUP COMPLETE")
    print("="*70)
    
    print("\nüìã NEXT STEPS:")
    print("1. Update .env file with your wallet and network settings:")
    print("   - WALLET_NAME=your_wallet_name")
    print("   - HOTKEY_NAME=your_hotkey_name")
    print("   - NETUID=44 (for mainnet)")
    print("   - SUBTENSOR_NETWORK=finney (for mainnet)")
    
    print("\n2. Register your IP on the network:")
    print("   fiber-post-ip --netuid 44 --subtensor.network finney \\")
    print("     --external_port 7999 --wallet.name YOUR_WALLET \\")
    print("     --wallet.hotkey YOUR_HOTKEY --external_ip YOUR_IP")
    
    print("\n3. Start the miner:")
    print("   ./start_miner.sh")
    
    print("\n4. Monitor performance:")
    print("   pm2 logs sn44-miner-rtx4090")
    print("   pm2 monit")
    
    print("\nüöÄ PERFORMANCE EXPECTATIONS:")
    print("   - Processing time: 2-8 seconds per challenge")
    print("   - GPU utilization: 80-95%")
    print("   - Memory usage: 8-12GB VRAM")
    print("   - Competitive leaderboard ranking")
    
    print("\n‚ö†Ô∏è IMPORTANT NOTES:")
    print("   - Keep TensorRT engines (.engine files) for fast startup")
    print("   - Monitor GPU temperature and power consumption")
    print("   - Check validator connectivity regularly")
    print("   - Update models and engines after driver updates")

async def main():
    """Main setup function."""
    logger.info("üöÄ Starting RTX 4090 Production Setup")
    
    # Check system requirements
    if not check_system_requirements():
        logger.error("‚ùå System requirements not met")
        return
    
    # Setup environment
    setup_environment()
    
    # Apply CUDA optimizations
    optimize_cuda_settings()
    
    # Download models
    logger.info("Downloading required models...")
    download_models()
    
    # Pre-compile TensorRT engines
    logger.info("Pre-compiling TensorRT engines...")
    if not precompile_engines():
        logger.error("‚ùå Engine compilation failed")
        return
    
    # Create startup script
    create_startup_script()
    
    # Run performance test
    logger.info("Running final performance test...")
    if await run_performance_test():
        logger.info("‚úÖ Performance test passed")
    else:
        logger.warning("‚ö†Ô∏è Performance test had issues - check configuration")
    
    # Print final instructions
    print_final_instructions()
    
    logger.info("üéâ RTX 4090 production setup complete!")

if __name__ == "__main__":
    asyncio.run(main()) 